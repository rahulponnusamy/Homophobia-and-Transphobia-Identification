{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert embedding with ML.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGNmCp9lgPCP"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive._mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "6CV5ik5Dgi_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Importing packages**"
      ],
      "metadata": {
        "id": "RXbbLL7Nuo0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import model_selection, naive_bayes\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.metrics import classification_report,confusion_matrix"
      ],
      "metadata": {
        "id": "DOao7X0gglu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**English dataset**"
      ],
      "metadata": {
        "id": "pQw_h4Uptmqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/Datasets/homo-trans/splited data/mini project II/eng/eng_train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/Datasets/homo-trans/splited data/mini project II/eng/eng_test.csv')"
      ],
      "metadata": {
        "id": "3SZgePKJgqjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.value_counts('category')"
      ],
      "metadata": {
        "id": "pWL57xKbmFTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.value_counts('category')"
      ],
      "metadata": {
        "id": "XWF2gOigmNmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Removing punctuations**"
      ],
      "metadata": {
        "id": "K7CJR3eKuLc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuations(txt):\n",
        "    text_nopunc=\"\".join([c for c in txt if c not in string.punctuation])\n",
        "    return text_nopunc\n",
        "\n",
        "train['text']=train['text'].apply(lambda x: remove_punctuations(x))\n",
        "test['text']=test['text'].apply(lambda x: remove_punctuations(x))"
      ],
      "metadata": {
        "id": "RtHPyjmSg1Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Encoding**"
      ],
      "metadata": {
        "id": "vMer1tqTuLc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Encoder = LabelEncoder()\n",
        "train['category']=Encoder.fit_transform(train['category'])\n",
        "test['category']=Encoder.fit_transform(test['category'])"
      ],
      "metadata": {
        "id": "x38_LtGog3LK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**BERT embedding**"
      ],
      "metadata": {
        "id": "ZN3Q05oQh_4Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKtCVaPch41o"
      },
      "outputs": [],
      "source": [
        "#function for selecting data for training\n",
        "def model_select(train,test):\n",
        "  X_train = train['text']\n",
        "  X_test = test['text']\n",
        "  y_train = train['category']\n",
        "  y_test = test['category']\n",
        "  return X_train, X_test, y_train, y_test\n",
        "\n",
        "#from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = model_select(train,test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "sbert_model = SentenceTransformer('nli-bert-large')  #nli-roberta-base-v2\n",
        "sbert_model = SentenceTransformer('nli-roberta-base-v2')\n",
        "f_train = sbert_model.encode(X_train)\n",
        "f_test = sbert_model.encode(X_test)"
      ],
      "metadata": {
        "id": "k2J9wQ0Zh_bB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Naive Bayes**"
      ],
      "metadata": {
        "id": "mGR8vGynhOO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "naive_bayes = BernoulliNB()\n",
        "# naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(f_train, y_train)\n",
        "pred_NB = naive_bayes.predict(f_test)"
      ],
      "metadata": {
        "id": "wpEYL_Sxbb9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test, pred_NB)) \n",
        "print(classification_report(y_test,pred_NB))"
      ],
      "metadata": {
        "id": "39uxqnf-bhHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Support Vector Machine**"
      ],
      "metadata": {
        "id": "WGrbyGPIhWun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normal SVM\n",
        "from sklearn.svm import SVC\n",
        "SVM = SVC(C=10, kernel = 'linear', degree = 3, class_weight='balanced'   , gamma = 'auto')\n",
        "X_Train_svm = SVM.fit(f_train, y_train)\n",
        "pred_svm = SVM.predict(f_test)"
      ],
      "metadata": {
        "id": "PIZTqKm5c_xT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test,pred_svm)) \n",
        "print(classification_report(y_test, pred_svm))"
      ],
      "metadata": {
        "id": "jjwPKpZcdCu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Logistic Regression**"
      ],
      "metadata": {
        "id": "bX7ONalrhc0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(C=2,class_weight = 'balanced',max_iter=1000)\n",
        "lr.fit(f_train,y_train)\n",
        "pred_LR = lr.predict(f_test)"
      ],
      "metadata": {
        "id": "Rggv1NCybFmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test,pred_LR)) \n",
        "print(classification_report(y_test,pred_LR))"
      ],
      "metadata": {
        "id": "oyLQoWvSbMPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Random Forest**"
      ],
      "metadata": {
        "id": "5Lb5i6LAhi9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler(with_mean=False)\n",
        "X_Train_RF = sc_X.fit_transform(f_train)\n",
        "test_RF = sc_X.transform(f_test)\n",
        "\n",
        "#Classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators=10, class_weight='balanced')\n",
        "classifier.fit(X_Train_RF, y_train)\n",
        "\n",
        "# Predicting the dev set \n",
        "Pred_RF = classifier.predict(test_RF)"
      ],
      "metadata": {
        "id": "X3FVseMCciQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test,Pred_RF))\n",
        "print(classification_report(y_test,Pred_RF))"
      ],
      "metadata": {
        "id": "_R_2YrsxcpG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Decision Tree**"
      ],
      "metadata": {
        "id": "ZAYZcwIkhoBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=0)\n",
        "clf = clf.fit(f_train, y_train)\n",
        "Pred_DT = clf.predict(f_test)"
      ],
      "metadata": {
        "id": "fyX945mXcyNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test,Pred_DT))\n",
        "print(classification_report(y_test,Pred_DT))"
      ],
      "metadata": {
        "id": "KY9NxCNcc0yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**XGBoost**"
      ],
      "metadata": {
        "id": "13iROIVphqiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "xgboost = XGBClassifier()\n",
        "xgboost.fit(np.array(f_train), y_train)\n",
        "pred_xg = xgboost.predict(f_test)"
      ],
      "metadata": {
        "id": "-8I_Fj45blwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test, pred_xg)) \n",
        "print(classification_report(y_test,pred_xg))"
      ],
      "metadata": {
        "id": "Pq9NLJZhbqGT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}